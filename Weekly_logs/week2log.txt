WEEK 2 LOG
Date: 11/16/2025 

Dataset Composition: 
- Utilized datasets containing 1,000 real face images and 1,000 AI-generated face images to effectively train the model.
- Split the dataset into 80% training and 20% testing for initial model evaluation.

Model Training:
- Based on insights from recent research papers, opted for a Convolutional Neural Network (CNN) approach, recognized for its effectiveness in visual pattern recognition.
- Referenced the original PyTorch documentation to ensure proper training procedures and model configuration.
- Hardware Upgrade: Transitioned from CPU to GPU, significantly accelerating the training process and enhancing computational efficiency.

Training Results:
- Initial Outcomes: Achieved 100% accuracy on the training dataset.
- This suggests that the dataset generated by the same generative AI model is too uniform and lacks diversity.
- This high accuracy suggests that the training set generated by the same AI model was overly uniform, indicating a potential overfitting issue due to a lack of diversity in the dataset.

Enhancing Diversity:
- Successfully sourced an additional 3,000 AI-generated and 3,000 real face images from various Kaggle datasets, greatly enhancing the diversity of the training dataset.
- Model maintained around 98% accuracy, but still struggled to recognize real photos from outside the dataset, classifying them predominantly as AI-generated.
- Removed 1,000 redundant real and 1,000 AI-generated images, and added more photographs from different Kaggle datasets to increase variability further.
- The dataset now consists of 5,000 real and 5,000 AI-generated images.
- Updated the split to 70% training, 20% testing, and 10% validation to better assess model performance.
- The model now retains 98% accuracy while also improving recognition of real photos from outside datasets, indicating progress toward generalization.

Conclusions:
- Choosing a diverse and representative dataset is crucial for training a robust model that can generalize well to unseen data.
- The transition to a more diverse dataset has yielded improvements in recognition capabilities, though challenges remain in addressing overfitting and model generalization.
- However, managing significantly larger datasets poses a challenge, and I recognize the need for more powerful computing resources to effectively train and evaluate the model in future phases of this project.

Further Plans:
- Investigate techniques to prevent overfitting, such as data augmentation, dropout layers, or regularization methods to enhance model generalization.
- Perform a comprehensive validation of the model on independent datasets to evaluate performance across different scenarios.
- Explore model optimization techniques and consider more powerful computing resources for handling larger datasets in future experiments.
- Plan to implement advanced CNN architectures or ensemble methods that may yield better performance metrics.

Literature:
https://www.researchgate.net/publication/394362952_A_Comparative_Survey_of_PyTorch_vs_TensorFlow_for_Deep_Learning_Usability_Performance_and_Deployment_Trade-offs
https://www.europol.europa.eu/cms/sites/default/files/documents/Europol_Innovation_Lab_Facing_Reality_Law_Enforcement_And_The_Challenge_Of_Deepfakes.pdf
https://www.researchgate.net/publication/394632447_Deepfake_detection_using_convolutional_neural_networks_a_deep_learning_approach_for_digital_security#:~:text=Through%20training%20with%20a%20dataset,is%20still%20room%20for%20improvement.

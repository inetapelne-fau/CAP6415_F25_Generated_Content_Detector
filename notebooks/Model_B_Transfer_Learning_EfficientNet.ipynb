{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0u1E5JZLTd5"
      },
      "source": [
        "# **Generated Content Detector Project: AI generated photos vs real photos**\n",
        "# **Transfer Learning - EfficientNet Model**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuVEMKm1jFj2"
      },
      "source": [
        "## **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade torchinfo"
      ],
      "metadata": {
        "id": "ZFRNcp15PFfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aDPk5LrLP1t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torchinfo import summary\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle\n",
        "from typing import List, Tuple\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "from timeit import default_timer as timer\n",
        "import random\n",
        "from sklearn.metrics import classification_report\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ex_sm4L9XX0"
      },
      "source": [
        "## **Downloading the dataset**\n",
        "###### The !gdown command downloads a specific file from Google Drive directly into the current working directory of the Jupyter notebook, using its unique file ID.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q1xldHl-CsZ"
      },
      "outputs": [],
      "source": [
        "!gdown 1u4xb45DdfP80kxJ20DV20qAGyhcDaCDL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DlmVsgHP2Fz"
      },
      "source": [
        "###### The !unzip command extracts the contents of the ZIP file above, decompressing the files into the current directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "y2XiF8c5-MxU"
      },
      "outputs": [],
      "source": [
        "!unzip /content/AI-face-detection-Dataset-v3.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_Cu3Yiuaqo8"
      },
      "source": [
        "## **Determining Optimal System Device for Performance: CPU vs. CUDA (VRAM)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOoO9TtsZFD5"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TFb-dZ3Jf6Q"
      },
      "source": [
        "## **Preparing Image Datasets with PyTorch.**\n",
        "##### **- Training Data: 7,000 images (3500 AI + 3500 real) - 70%**\n",
        "##### **- Testing Data: 2,000 images (1000 AI + 1000 real) - 20%**\n",
        "##### **- Testing Data: 1,000 images (500 AI + 500 real) - 10%**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEsPZLZlJImm"
      },
      "outputs": [],
      "source": [
        "# Measure the time taken for the cell execution:\n",
        "%%time\n",
        "\n",
        "# Set up image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the dataset from the specified directory\n",
        "dataset = datasets.ImageFolder(\"/content/AI-face-detection-Dataset-v3/\", transform=transform)\n",
        "\n",
        "# Load previously saved indices or datasets if available:\n",
        "try:\n",
        "    with open('datasets.pkl', 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "        train_indices = data['train_indices']\n",
        "        val_indices = data['val_indices']\n",
        "        test_indices = data['test_indices']\n",
        "        classes = data['classes']\n",
        "except FileNotFoundError:\n",
        "    print(\"No saved dataset found, proceeding with the current run.\")\n",
        "\n",
        "# If loading fails, do the following steps:\n",
        "\n",
        "# Split by class (real + ai separately)\n",
        "indices_real = [i for i, (_, label) in enumerate(dataset) if label == dataset.class_to_idx[\"real_color\"]]\n",
        "indices_ai   = [i for i, (_, label) in enumerate(dataset) if label == dataset.class_to_idx[\"AI\"]]\n",
        "\n",
        "# Train size 70%, Validation size 10%, Test size 20%\n",
        "def split_class(indices, train_ratio=0.7, val_ratio=0.1):\n",
        "    train_len = int(len(indices) * train_ratio)\n",
        "    val_len = int(len(indices) * val_ratio)\n",
        "    return indices[:train_len], indices[train_len:train_len + val_len], indices[train_len + val_len:]\n",
        "\n",
        "train_real, val_real, test_real = split_class(indices_real)\n",
        "train_ai, val_ai, test_ai = split_class(indices_ai)\n",
        "\n",
        "# Combine training, validation, and testing indices\n",
        "train_indices = train_real + train_ai\n",
        "val_indices = val_real + val_ai\n",
        "test_indices = test_real + test_ai\n",
        "\n",
        "# Prepare subsets for training, validation, and testing\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "test_dataset = Subset(dataset, test_indices)\n",
        "\n",
        "# Create data loaders for batch processing\n",
        "trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2)  # Validation loader\n",
        "testloader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "# Retrieve class names\n",
        "classes = dataset.classes   # ['ai', 'real']\n",
        "\n",
        "# Output the number of samples in training, validation, and testing datasets\n",
        "print(\"Train samples:\", len(train_indices))\n",
        "print(\"Validation samples:\", len(val_indices))\n",
        "print(\"Test samples:\", len(test_indices))\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "# Save the datasets and indices:\n",
        "with open('datasets.pkl', 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'train_indices': train_indices,\n",
        "        'val_indices': val_indices,\n",
        "        'test_indices': test_indices,\n",
        "        'classes': classes\n",
        "    }, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y2ClMIffggE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setting up a pretrained model - 'EfficientNet-B0'**"
      ],
      "metadata": {
        "id": "PtQmJ8m_PQGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # Selects the best available weights\n",
        "model = torchvision.models.efficientnet_b0(weights=weights).to(device)"
      ],
      "metadata": {
        "id": "yTGZbWMOPTJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Getting a summary of our model with torchinfo.summary()**\n",
        "###### Overall, the EfficientNet-B0 model is well-structured and efficient, with a significant number of parameters that should allow for high performance in tasks such as face content detection. The shapes of inputs and outputs reflect the architecture's adaptability, while the total parameter count suggests a balance between complexity and efficiency."
      ],
      "metadata": {
        "id": "uvX5iiP6PQH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model,\n",
        "        input_size=(8, 3, 128, 128), # The size of the input tensor (batch size, channels, height, width)\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], # Specifies the columns to display in the summary\n",
        "        col_width=20, # Sets the width of the columns in the summary output\n",
        "        row_settings=[\"var_names\"]) # Includes variable names in the summary rows for clarity"
      ],
      "metadata": {
        "id": "fvThgtXvPp5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The model summary illustrates the notable transformations in input and output shapes as the image data navigates through the EfficientNet-B0 architecture. Boasting a total of 5,288,548 parameters, this model is well-prepared to identify a wide range of patterns within the data. The plan is to freeze the base model to retain the learned features and modify the output layer to tailor it to specific requirements, leveraging this increased capacity for enhanced performance in the application."
      ],
      "metadata": {
        "id": "msHDRMM8PQJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Freezing All Layers of the Base Model Except the Last Layer**\n",
        "###### Freezing all layers of the base model except the last layer during transfer learning helps preserve the learned low-level features from the pre-trained model, preventing overfitting, especially with smaller datasets. It allows the model to adapt specifically to the new task by fine-tuning only the last layer, which is more task-specific, while maintaining the foundational knowledge. This approach also accelerates training and stabilizes the learning process in the early epochs."
      ],
      "metadata": {
        "id": "_Wg4W-cyPQP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.features[-1:].parameters(): # Access the parameters of the last layer in the features section\n",
        "    param.requires_grad = True # Enables this parameter to be updated during backpropagation"
      ],
      "metadata": {
        "id": "gEyjr_zYQJ5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Get the length of classes (one output unit for each class)\n",
        "output_shape = len(classes)\n",
        "\n",
        "# Recreate the classifier layer and seed it to the target device\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=1280,\n",
        "                    out_features=output_shape, # same number of output units as our number of classes\n",
        "                    bias=True)).to(device)"
      ],
      "metadata": {
        "id": "SjCCcyxKQJ8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Do a summary *after* freezing the features and changing the output classifier layer\n",
        "summary(model,\n",
        "        input_size=(8, 3, 128, 128), # (batch_size, color_channels, height, width)\n",
        "        verbose=0,\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "id": "25Rde9SCQJ-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### After freezing all but the last layer of the base model, the total parameters decreased from 5,288,548 to 4,010,110, indicating a reduction in model complexity. All remaining parameters are still trainable, allowing adaptation to the specific task. Despite this reduction, memory usage and compute requirements for forward and backward passes remained similar, which enhances training efficiency while maintaining performance.\n"
      ],
      "metadata": {
        "id": "4iZK9XAFahJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training the model**"
      ],
      "metadata": {
        "id": "wXl_eloePQSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function for training\n",
        "loss_fn = nn.CrossEntropyLoss() # This is used for multi-class classification\n",
        "\n",
        "# Set up the optimizer for updating the model's parameters\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # Stochastic Gradient Descent with momentum\n",
        "\n",
        "# Alternative optimizer: Adam optimizer for adaptive learning rate\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "ucbZ3v8VQ3gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ENGINE\n",
        "\"\"\"\n",
        "Contains functions for training and testing a PyTorch model.\n",
        "\"\"\"\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "    \"\"\"Trains a PyTorch model for a single epoch.\n",
        "\n",
        "    Turns a target PyTorch model to training mode and then\n",
        "    runs through all of the required training steps (forward\n",
        "    pass, loss calculation, optimizer step).\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be trained.\n",
        "    dataloader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy).\n",
        "    For example:(0.1112, 0.8743)\n",
        "    \"\"\"\n",
        "    # Put model in train mode to enable training features\n",
        "    model.train()\n",
        "\n",
        "    # Initialize train loss and train accuracy values\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Loop through batches of data from the dataloader\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # # Send data to the specified target device (GPU/CPU)\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass: get predictions from the model\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate and accumulate loss using the loss function\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item() # Accumulate loss for average calculation\n",
        "\n",
        "        # # 3. Optimizer zero grad: clear old gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward: compute gradients of loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. . Optimizer step: update model parameters based on gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate and accumulate accuracy metric across all batches\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader) # Average loss over batches\n",
        "    train_acc = train_acc / len(dataloader) # Average accuracy over batches\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "    \"\"\"Tests a PyTorch model for a single epoch.\n",
        "\n",
        "    Turns a target PyTorch model to \"eval\" mode and then performs\n",
        "    a forward pass on a testing dataset.\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be tested.\n",
        "    dataloader: A DataLoader instance for the model to be tested on.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A tuple of testing loss and testing accuracy metrics.\n",
        "    In the form (test_loss, test_accuracy).\n",
        "    For example: (0.0223, 0.8985)\n",
        "    \"\"\"\n",
        "    # Put model in eval mode to deactivate dropout layers and batch norm behavior\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference context manager to save memory during inference\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches for testing\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to the specified target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass: get predictions from the model\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate and accumulate loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item() # Accumulate loss for average calculation\n",
        "\n",
        "            # Calculate and accumulate accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for\n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "              train_acc: [...],\n",
        "              test_loss: [...],\n",
        "              test_acc: [...]}\n",
        "    For example if training for epochs=2:\n",
        "             {train_loss: [2.0616, 1.0537],\n",
        "              train_acc: [0.3945, 0.3945],\n",
        "              test_loss: [1.2641, 1.5706],\n",
        "              test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Make sure model on target device\n",
        "    model.to(device)\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results"
      ],
      "metadata": {
        "id": "bXiUpXP1RCWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seeds for reproducibility in training\n",
        "torch.manual_seed(42).       # Set seed for CPU\n",
        "torch.cuda.manual_seed(42).  # Set seed for GPU\n",
        "\n",
        "# Start the timer to measure training duration\n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "results = train(model=model,\n",
        "                       train_dataloader=trainloader,  # DataLoader for training data\n",
        "                       test_dataloader=valloader, # DataLoader for validation/testing data\n",
        "                       optimizer=optimizer, # Optimizer for model training\n",
        "                       loss_fn=loss_fn, # Loss function to evaluate model performance\n",
        "                       epochs=10, # Number of training epochs\n",
        "                       device=device) # Device to perform training (CPU or GPU)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "OKIVkcxgRjVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Learning Curve**"
      ],
      "metadata": {
        "id": "gh8HzbNZQ4Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves of a model\n",
        "def plot_loss_curves(results):\n",
        "    \"\"\"Plots training curves of a results dictionary.\n",
        "\n",
        "    Args:\n",
        "        results (dict): dictionary containing list of values, e.g.\n",
        "            {\"train_loss\": [...],\n",
        "             \"train_acc\": [...],\n",
        "             \"test_loss\": [...],\n",
        "             \"test_acc\": [...]}\n",
        "    \"\"\"\n",
        "    loss = results[\"train_loss\"]\n",
        "    test_loss = results[\"test_loss\"]\n",
        "\n",
        "    accuracy = results[\"train_acc\"]\n",
        "    test_accuracy = results[\"test_acc\"]\n",
        "\n",
        "    epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, label=\"train_loss\")\n",
        "    plt.plot(epochs, test_loss, label=\"test_loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
        "    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "G2x6Y--zRvZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves of our model\n",
        "plot_loss_curves(results)"
      ],
      "metadata": {
        "id": "qZW5zySXR9IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The learning curves indicate a positive training process, with the training loss decreasing steadily over epochs, reflecting effective learning and adaptation to the training data. The test loss also declines, showcasing good generalization to unseen data, as evidenced by the minimal gap between training and test losses. Both training and test accuracies approach 100%, suggesting that the model is fitting well to the training set while also performing excellently on the validation set. Overall, the curves demonstrate that the model is neither overfitting nor underfitting, indicating a well-tuned performance throughout the training process."
      ],
      "metadata": {
        "id": "amI894uce8BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validation Accuracy**"
      ],
      "metadata": {
        "id": "vwBBt4f-xwJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best saved model\n",
        "# The 'Net' class is not defined, using the 'model' variable from previous cells.\n",
        "best_model = model\n",
        "# The model is already loaded and trained, so no need to load state dict again.\n",
        "# best_model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in valloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = best_model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "final_val_accuracy = correct / total\n",
        "print(f\"Final Validation Accuracy (best model): {final_val_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "UeM_ju9XxxEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### This impressive validation accuracy of 0.9860 demonstrates that the model has effectively learned from the training data and is performing exceptionally well on unseen data, highlighting its strong generalization capabilities while showing no signs of overfitting."
      ],
      "metadata": {
        "id": "2AOwuciiH3ig"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euxZpWXdV0rC"
      },
      "source": [
        "## **Testing the Network on Test Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14e4dfa2"
      },
      "source": [
        "#### Preparing and Predicting Test Images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b847055"
      },
      "source": [
        "model.eval() # Set the model to evaluation mode\n",
        "\n",
        "dataiter = iter(testloader)  # Create an iterator for the test data loader\n",
        "images, true_labels = next(dataiter)  # Get a batch of images and their true labels\n",
        "\n",
        "images = images.to(device)  # Move images to the appropriate device\n",
        "\n",
        "# Perform a forward pass and get predictions without calculating gradients\n",
        "with torch.no_grad():\n",
        "    outputs = model(images)\n",
        "\n",
        "_, predicted_labels = torch.max(outputs, 1) # Get the predicted class indices\n",
        "\n",
        "print(\"Retrieved a batch of test images and generated predictions.\")\n",
        "print(f\"Number of images in batch: {len(images)}\")\n",
        "print(f\"True labels (first 10): {true_labels[:10].tolist()}\")\n",
        "print(f\"Predicted labels (first 10): {predicted_labels[:10].tolist()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86a38584"
      },
      "source": [
        "#### Displaying Images with Actual and Predicted Labels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22b514b8"
      },
      "source": [
        "num_display = 10\n",
        "\n",
        "fig = plt.figure(figsize=(15, 6))\n",
        "\n",
        "for idx in range(num_display):\n",
        "    ax = fig.add_subplot(2, 5, idx + 1, xticks=[], yticks=[])\n",
        "\n",
        "    # Unnormalize the image and transpose dimensions\n",
        "    img_display = images[idx].cpu().numpy()\n",
        "    img_display = img_display / 2 + 0.5\n",
        "    img_display = np.transpose(img_display, (1, 2, 0))\n",
        "\n",
        "    # Display the image\n",
        "    ax.imshow(img_display)\n",
        "\n",
        "    # Set title with true and predicted labels\n",
        "    ax.set_title(f\"True: {classes[true_labels[idx]]}\\nPred: {classes[predicted_labels[idx]]}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24YCjlPzrVIa"
      },
      "source": [
        "## **Evaluating Network Performance on the Entire Dataset**\n",
        "### **Overall Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2APmVrqSrRI8"
      },
      "outputs": [],
      "source": [
        "correct = 0  # Initialize a counter for correctly classified images\n",
        "total = 0    # Initialize a counter for the total number of images\n",
        "\n",
        "# Disable gradient calculation for evaluation\n",
        "with torch.no_grad():\n",
        "    for data in testloader:  # Iterate through batches of test data\n",
        "        images, labels = data  # Get images and their corresponding labels\n",
        "\n",
        "        # Move inputs to the appropriate device for processing\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Calculate outputs by passing images through the network\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Determine the predicted class by finding the index of the highest score\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)  # Update the total number of images processed\n",
        "        correct += (predicted == labels).sum().item()  # Count correct predictions\n",
        "\n",
        "# Calculate and print the accuracy of the network on the test dataset\n",
        "accuracy = 100 * correct / total if total > 0 else 0  # Prevent division by zero\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f} %')  # Print accuracy formatted to two decimal places"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The model achieved a test accuracy of 98.75%, further underscoring its exceptional performance and robust generalization capabilities on unseen data."
      ],
      "metadata": {
        "id": "RCqB2pLif0Lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Classification Report**"
      ],
      "metadata": {
        "id": "6vvv_QdoTh2Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "876bfc91"
      },
      "source": [
        "# Ensure the model is in evaluation mode and on the correct device\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "\n",
        "# Disable gradient calculation for efficiency during evaluation\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(all_labels, all_predictions, target_names=classes)\n",
        "\n",
        "# Print the report\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The classification report shows outstanding performance, with precision of 0.98 for \"AI\" and 0.99 for \"real,\" indicating low false positives. Both classes achieved high recall values of 0.99 and 0.98, reflecting minimal false negatives. With F1-scores of 0.99 and an overall accuracy of 0.99, the model demonstrates exceptional reliability in distinguishing between AI-generated and real images."
      ],
      "metadata": {
        "id": "M-kW1CRDgXVD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRcUd2_YkuA6"
      },
      "source": [
        "### **Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9529e048"
      },
      "outputs": [],
      "source": [
        "# Ensure the model is in evaluation mode and on the correct device\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "\n",
        "# Disable gradient calculation for efficiency during evaluation\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The confusion matrix highlights the model's strong performance, accurately classifying 992 out of 1,001 \"AI\" images, resulting in just 9 false negatives. For the \"real_color\" class, 985 of 1,001 were correctly predicted, with 16 false positives. The significant diagonal values compared to the off-diagonal entries demonstrate the model's effectiveness in distinguishing between the two classes with minimal misclassifications."
      ],
      "metadata": {
        "id": "Mw6NA7hGkcs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Summary:** The model demonstrates exceptional performance across all metrics, achieving a validation accuracy of 98.6% and a test accuracy of 98.8%. The classification report shows high precision and recall values, both around 0.99, indicating effective identification of both \"AI\" and \"real\" classes. The confusion matrix further confirms this with minimal misclassifications, highlighting the model's robust generalization capabilities and reliability in distinguishing between AI-generated and real images."
      ],
      "metadata": {
        "id": "VRUFpJWYeRRw"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
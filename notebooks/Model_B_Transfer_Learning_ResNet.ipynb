{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0u1E5JZLTd5"
      },
      "source": [
        "# **Generated Content Detector Project: AI generated photos vs real photos**\n",
        "# **Transfer Learning - ResNet Model**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuVEMKm1jFj2"
      },
      "source": [
        "## **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade torchinfo"
      ],
      "metadata": {
        "id": "ZFRNcp15PFfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aDPk5LrLP1t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torchinfo import summary\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle\n",
        "from typing import List, Tuple\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "from timeit import default_timer as timer\n",
        "import random\n",
        "from sklearn.metrics import classification_report\n",
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ex_sm4L9XX0"
      },
      "source": [
        "## **Downloading the dataset**\n",
        "###### The !gdown command downloads a specific file from Google Drive directly into the current working directory of the Jupyter notebook, using its unique file ID.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q1xldHl-CsZ"
      },
      "outputs": [],
      "source": [
        "!gdown 1u4xb45DdfP80kxJ20DV20qAGyhcDaCDL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DlmVsgHP2Fz"
      },
      "source": [
        "###### The !unzip command extracts the contents of the ZIP file above, decompressing the files into the current directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "y2XiF8c5-MxU"
      },
      "outputs": [],
      "source": [
        "!unzip /content/AI-face-detection-Dataset-v3.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_Cu3Yiuaqo8"
      },
      "source": [
        "## **Determining Optimal System Device for Performance: CPU vs. CUDA (VRAM)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOoO9TtsZFD5"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TFb-dZ3Jf6Q"
      },
      "source": [
        "## **Preparing Image Datasets with PyTorch.**\n",
        "##### **- Training Data: 7,000 images (3500 AI + 3500 real) - 70%**\n",
        "##### **- Testing Data: 2,000 images (1000 AI + 1000 real) - 20%**\n",
        "##### **- Testing Data: 1,000 images (500 AI + 500 real) - 10%**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEsPZLZlJImm"
      },
      "outputs": [],
      "source": [
        "# Measure the time taken for the cell execution:\n",
        "%%time\n",
        "\n",
        "# Set up image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the dataset from the specified directory\n",
        "dataset = datasets.ImageFolder(\"/content/AI-face-detection-Dataset-v3/\", transform=transform)\n",
        "\n",
        "# Load previously saved indices or datasets if available:\n",
        "try:\n",
        "    with open('datasets.pkl', 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "        train_indices = data['train_indices']\n",
        "        val_indices = data['val_indices']\n",
        "        test_indices = data['test_indices']\n",
        "        classes = data['classes']\n",
        "except FileNotFoundError:\n",
        "    print(\"No saved dataset found, proceeding with the current run.\")\n",
        "\n",
        "# If loading fails, do the following steps:\n",
        "\n",
        "# Split by class (real + ai separately)\n",
        "indices_real = [i for i, (_, label) in enumerate(dataset) if label == dataset.class_to_idx[\"real_color\"]]\n",
        "indices_ai   = [i for i, (_, label) in enumerate(dataset) if label == dataset.class_to_idx[\"AI\"]]\n",
        "\n",
        "# Train size 70%, Validation size 10%, Test size 20%\n",
        "def split_class(indices, train_ratio=0.7, val_ratio=0.1):\n",
        "    train_len = int(len(indices) * train_ratio)\n",
        "    val_len = int(len(indices) * val_ratio)\n",
        "    return indices[:train_len], indices[train_len:train_len + val_len], indices[train_len + val_len:]\n",
        "\n",
        "train_real, val_real, test_real = split_class(indices_real)\n",
        "train_ai, val_ai, test_ai = split_class(indices_ai)\n",
        "\n",
        "# Combine training, validation, and testing indices\n",
        "train_indices = train_real + train_ai\n",
        "val_indices = val_real + val_ai\n",
        "test_indices = test_real + test_ai\n",
        "\n",
        "# Prepare subsets for training, validation, and testing\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "test_dataset = Subset(dataset, test_indices)\n",
        "\n",
        "# Create data loaders for batch processing\n",
        "trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=2)  # Validation loader\n",
        "testloader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "# Retrieve class names\n",
        "classes = dataset.classes   # ['ai', 'real']\n",
        "\n",
        "# Output the number of samples in training, validation, and testing datasets\n",
        "print(\"Train samples:\", len(train_indices))\n",
        "print(\"Validation samples:\", len(val_indices))\n",
        "print(\"Test samples:\", len(test_indices))\n",
        "print(\"Classes:\", classes)\n",
        "\n",
        "# Save the datasets and indices:\n",
        "with open('datasets.pkl', 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'train_indices': train_indices,\n",
        "        'val_indices': val_indices,\n",
        "        'test_indices': test_indices,\n",
        "        'classes': classes\n",
        "    }, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setting up a pretrained model - 'ResNet18'**"
      ],
      "metadata": {
        "id": "PtQmJ8m_PQGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
        "weights = torchvision.models.ResNet18_Weights.DEFAULT # Selects the best available weights\n",
        "model = torchvision.models.resnet18(weights=weights).to(device)"
      ],
      "metadata": {
        "id": "yTGZbWMOPTJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Getting a summary of our model with torchinfo.summary()**\n",
        "###### Overall, the ResNet-18 model is well-structured and efficient, with a substantial number of parameters that enable high performance in tasks such as content detection. The shapes of inputs and outputs reflect the architecture’s adaptability, while the total parameter count indicates a balance between complexity and efficiency."
      ],
      "metadata": {
        "id": "uvX5iiP6PQH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model,\n",
        "        input_size=(8, 3, 128, 128), # The size of the input tensor (batch size, channels, height, width)\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], # Specifies the columns to display in the summary\n",
        "        col_width=20, # Sets the width of the columns in the summary output\n",
        "        row_settings=[\"var_names\"]) # Includes variable names in the summary rows for clarity"
      ],
      "metadata": {
        "id": "fvThgtXvPp5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Freezing All Layers of the Base Model Except the Last Three Layers**\n",
        "###### The model summary illustrates the notable transformations in input and output shapes as the image data navigates through the ResNet architecture. Boasting a total of 11,689,512 parameters, this model is well-prepared to identify a wide range of patterns within the data. The plan is to freeze the majority of the base model to retain learned features, prevent overfitting, and ensure faster training. This will allow the model to maintain stability in learning while focusing on task-specific adaptations. Selectively unfreezing the last layers will enable fine-tuning for specific tasks, thereby enhancing performance in the application."
      ],
      "metadata": {
        "id": "_Wg4W-cyPQP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False # Freeze all base layers"
      ],
      "metadata": {
        "id": "gEyjr_zYQJ5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0508738f"
      },
      "source": [
        "### **Unfreezing `model.layer3` for Fine-tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5365fcf"
      },
      "source": [
        "# Unfreeze parameters in model.layer3\n",
        "for param in model.layer3.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\"Parameters in model.layer3 are now unfrozen.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2231e279"
      },
      "source": [
        "### **Model Summary After Unfreezing `model.layer3` and `model.fc`**\n",
        "\n",
        "Let's re-examine the model summary to see the updated number of trainable parameters after unfreezing `model.layer3` (in addition to the `fc` layer)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Get the length of classes (one output unit for each class)\n",
        "output_shape = len(classes)\n",
        "\n",
        "# Recreate the final fully connected layer (fc) for ResNet18 and send it to the target device\n",
        "# ResNet18's final layer is named 'fc', and its input features are 512 after the AdaptiveAvgPool2d.\n",
        "model.fc = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2),\n",
        "    torch.nn.Linear(in_features=512, # ResNet18's 'fc' layer takes 512 in_features\n",
        "                    out_features=output_shape, # same number of output units as our number of classes\n",
        "                    bias=True)).to(device)\n"
      ],
      "metadata": {
        "id": "SjCCcyxKQJ8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bda2230a"
      },
      "source": [
        "# Do a summary *after* unfreezing model.layer3 and model.fc\n",
        "summary(model,\n",
        "        input_size=(8, 3, 128, 128), # (batch_size, color_channels, height, width)\n",
        "        verbose=0,\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The primary change after freezing/unfreezing is a significant reduction in trainable parameters from 11,177,538 to 2,100,738, indicating that only certain layers are now updated during training, while 9,076,800 parameters remain frozen. This approach retains learned features in the base layers, reducing the risk of overfitting, while still leveraging the model's computational capacity as indicated by the constant total mult-adds and estimation sizes. The unchanged input size and forward/backward pass sizes suggest that the model’s computational efficiency remains intact, facilitating quicker training iterations while focusing on task-specific learning in the unfrozen layers.\n"
      ],
      "metadata": {
        "id": "4iZK9XAFahJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training the model**"
      ],
      "metadata": {
        "id": "wXl_eloePQSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function for training\n",
        "loss_fn = nn.CrossEntropyLoss() # This is used for multi-class classification\n",
        "\n",
        "# Set up the optimizer for updating the model's parameters\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # Stochastic Gradient Descent with momentum\n",
        "\n",
        "# Alternative optimizer: Adam optimizer for adaptive learning rate\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "ucbZ3v8VQ3gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ENGINE\n",
        "\"\"\"\n",
        "Contains functions for training and testing a PyTorch model.\n",
        "\"\"\"\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "    \"\"\"Trains a PyTorch model for a single epoch.\n",
        "\n",
        "    Turns a target PyTorch model to training mode and then\n",
        "    runs through all of the required training steps (forward\n",
        "    pass, loss calculation, optimizer step).\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be trained.\n",
        "    dataloader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy).\n",
        "    For example:(0.1112, 0.8743)\n",
        "    \"\"\"\n",
        "    # Put model in train mode to enable training features\n",
        "    model.train()\n",
        "\n",
        "    # Initialize train loss and train accuracy values\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Loop through batches of data from the dataloader\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # # Send data to the specified target device (GPU/CPU)\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass: get predictions from the model\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate and accumulate loss using the loss function\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item() # Accumulate loss for average calculation\n",
        "\n",
        "        # # 3. Optimizer zero grad: clear old gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward: compute gradients of loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. . Optimizer step: update model parameters based on gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate and accumulate accuracy metric across all batches\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader) # Average loss over batches\n",
        "    train_acc = train_acc / len(dataloader) # Average accuracy over batches\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "    \"\"\"Tests a PyTorch model for a single epoch.\n",
        "\n",
        "    Turns a target PyTorch model to \"eval\" mode and then performs\n",
        "    a forward pass on a testing dataset.\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be tested.\n",
        "    dataloader: A DataLoader instance for the model to be tested on.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A tuple of testing loss and testing accuracy metrics.\n",
        "    In the form (test_loss, test_accuracy).\n",
        "    For example: (0.0223, 0.8985)\n",
        "    \"\"\"\n",
        "    # Put model in eval mode to deactivate dropout layers and batch norm behavior\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference context manager to save memory during inference\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches for testing\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to the specified target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass: get predictions from the model\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate and accumulate loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item() # Accumulate loss for average calculation\n",
        "\n",
        "            # Calculate and accumulate accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for\n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "              train_acc: [...],\n",
        "              test_loss: [...],\n",
        "              test_acc: [...]}\n",
        "    For example if training for epochs=2:\n",
        "             {train_loss: [2.0616, 1.0537],\n",
        "              train_acc: [0.3945, 0.3945],\n",
        "              test_loss: [1.2641, 1.5706],\n",
        "              test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Make sure model on target device\n",
        "    model.to(device)\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results"
      ],
      "metadata": {
        "id": "bXiUpXP1RCWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seeds for reproducibility in training\n",
        "torch.manual_seed(42)       # Set seed for CPU\n",
        "torch.cuda.manual_seed(42)  # Set seed for GPU\n",
        "\n",
        "# Start the timer to measure training duration\n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "results = train(model=model,\n",
        "                       train_dataloader=trainloader,  # DataLoader for training data\n",
        "                       test_dataloader=valloader, # DataLoader for validation/testing data\n",
        "                       optimizer=optimizer, # Optimizer for model training\n",
        "                       loss_fn=loss_fn, # Loss function to evaluate model performance\n",
        "                       epochs=8, # Number of training epochs\n",
        "                       device=device) # Device to perform training (CPU or GPU)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "OKIVkcxgRjVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Learning Curve**"
      ],
      "metadata": {
        "id": "gh8HzbNZQ4Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot loss curves of a model\n",
        "def plot_loss_curves(results):\n",
        "    \"\"\"Plots training curves of a results dictionary.\n",
        "\n",
        "    Args:\n",
        "        results (dict): dictionary containing list of values, e.g.\n",
        "            {\"train_loss\": [...],\n",
        "             \"train_acc\": [...],\n",
        "             \"test_loss\": [...],\n",
        "             \"test_acc\": [...]}\n",
        "    \"\"\"\n",
        "    loss = results[\"train_loss\"]\n",
        "    test_loss = results[\"test_loss\"]\n",
        "\n",
        "    accuracy = results[\"train_acc\"]\n",
        "    test_accuracy = results[\"test_acc\"]\n",
        "\n",
        "    epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, label=\"train_loss\")\n",
        "    plt.plot(epochs, test_loss, label=\"test_loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
        "    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "G2x6Y--zRvZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves of our model\n",
        "plot_loss_curves(results)"
      ],
      "metadata": {
        "id": "qZW5zySXR9IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The learning curves for ResNet18 show a steady decrease in training loss and a corresponding improvement in training accuracy, indicating effective learning and a good fit to the training data. The test loss also trends downward, suggesting strong generalization to unseen data, while the test accuracy approaches near-perfect values. The close alignment of training and test metrics implies minimal overfitting, affirming that the model is well-tuned for the task at hand. Overall, these curves demonstrate the model's robustness and make a compelling case for its application in image classification and related tasks."
      ],
      "metadata": {
        "id": "amI894uce8BS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validation Accuracy**"
      ],
      "metadata": {
        "id": "vwBBt4f-xwJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best saved model\n",
        "# The 'Net' class is not defined, using the 'model' variable from previous cells.\n",
        "best_model = model\n",
        "# The model is already loaded and trained, so no need to load state dict again.\n",
        "# best_model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
        "best_model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in valloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = best_model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "final_val_accuracy = correct / total\n",
        "print(f\"Final Validation Accuracy (best model): {final_val_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "UeM_ju9XxxEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The final validation accuracy indicates that the model performed exceptionally well, successfully classifying 99% of the validation samples correctly. This high accuracy demonstrates strong generalization capabilities and suggests that the model is well-suited for the task, minimizing errors on unseen data."
      ],
      "metadata": {
        "id": "2AOwuciiH3ig"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euxZpWXdV0rC"
      },
      "source": [
        "## **Testing the Network on Test Data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14e4dfa2"
      },
      "source": [
        "#### Preparing and Predicting Test Images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b847055"
      },
      "source": [
        "model.eval() # Set the model to evaluation mode\n",
        "\n",
        "dataiter = iter(testloader)  # Create an iterator for the test data loader\n",
        "images, true_labels = next(dataiter)  # Get a batch of images and their true labels\n",
        "\n",
        "images = images.to(device)  # Move images to the appropriate device\n",
        "\n",
        "# Perform a forward pass and get predictions without calculating gradients\n",
        "with torch.no_grad():\n",
        "    outputs = model(images)\n",
        "\n",
        "_, predicted_labels = torch.max(outputs, 1) # Get the predicted class indices\n",
        "\n",
        "print(\"Retrieved a batch of test images and generated predictions.\")\n",
        "print(f\"Number of images in batch: {len(images)}\")\n",
        "print(f\"True labels (first 10): {true_labels[:10].tolist()}\")\n",
        "print(f\"Predicted labels (first 10): {predicted_labels[:10].tolist()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86a38584"
      },
      "source": [
        "#### Displaying Images with Actual and Predicted Labels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22b514b8"
      },
      "source": [
        "num_display = 10\n",
        "\n",
        "fig = plt.figure(figsize=(15, 6))\n",
        "\n",
        "for idx in range(num_display):\n",
        "    ax = fig.add_subplot(2, 5, idx + 1, xticks=[], yticks=[])\n",
        "\n",
        "    # Unnormalize the image and transpose dimensions\n",
        "    img_display = images[idx].cpu().numpy()\n",
        "    img_display = img_display / 2 + 0.5\n",
        "    img_display = np.transpose(img_display, (1, 2, 0))\n",
        "\n",
        "    # Display the image\n",
        "    ax.imshow(img_display)\n",
        "\n",
        "    # Set title with true and predicted labels\n",
        "    ax.set_title(f\"True: {classes[true_labels[idx]]}\\nPred: {classes[predicted_labels[idx]]}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24YCjlPzrVIa"
      },
      "source": [
        "## **Evaluating Network Performance on the Entire Dataset**\n",
        "### **Overall Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2APmVrqSrRI8"
      },
      "outputs": [],
      "source": [
        "correct = 0  # Initialize a counter for correctly classified images\n",
        "total = 0    # Initialize a counter for the total number of images\n",
        "\n",
        "# Disable gradient calculation for evaluation\n",
        "with torch.no_grad():\n",
        "    for data in testloader:  # Iterate through batches of test data\n",
        "        images, labels = data  # Get images and their corresponding labels\n",
        "\n",
        "        # Move inputs to the appropriate device for processing\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Calculate outputs by passing images through the network\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Determine the predicted class by finding the index of the highest score\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)  # Update the total number of images processed\n",
        "        correct += (predicted == labels).sum().item()  # Count correct predictions\n",
        "\n",
        "# Calculate and print the accuracy of the network on the test dataset\n",
        "accuracy = 100 * correct / total if total > 0 else 0  # Prevent division by zero\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f} %')  # Print accuracy formatted to two decimal places"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The test accuracy of 98.90% shows that the model reliably classifies nearly all unseen samples correctly, confirming its strong performance and generalization ability."
      ],
      "metadata": {
        "id": "RCqB2pLif0Lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Classification Report**"
      ],
      "metadata": {
        "id": "6vvv_QdoTh2Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "876bfc91"
      },
      "source": [
        "# Ensure the model is in evaluation mode and on the correct device\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "\n",
        "# Disable gradient calculation for efficiency during evaluation\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(all_labels, all_predictions, target_names=classes)\n",
        "\n",
        "# Print the report\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The classification report shows excellent performance, with both classes achieving precision, recall, and F1-scores of 0.99, indicating minimal errors. The overall accuracy of 0.99 confirms the model's robustness in accurately classifying the dataset."
      ],
      "metadata": {
        "id": "M-kW1CRDgXVD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRcUd2_YkuA6"
      },
      "source": [
        "### **Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9529e048"
      },
      "outputs": [],
      "source": [
        "# Ensure the model is in evaluation mode and on the correct device\n",
        "model.eval()\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "\n",
        "# Disable gradient calculation for efficiency during evaluation\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The confusion matrix highlights strong model performance, correctly classifying 991 out of 1,001 \"AI\" images and 989 out of 1,001 \"real\" images. The low number of misclassifications - 10 false positives and 12 false negatives - demonstrates the model's effectiveness in distinguishing between the two classes."
      ],
      "metadata": {
        "id": "Mw6NA7hGkcs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Summary:** The model exhibits outstanding performance, with a validation accuracy of 99.0% and a test accuracy of 98.9%. The classification report reveals high precision and recall values of 0.99 for both \"AI\" and \"real\" classes, showcasing effective identification. The confusion matrix further supports these findings, showing minimal misclassifications, which underscores the model's robust generalization capabilities and reliability in distinguishing between AI-generated and real images."
      ],
      "metadata": {
        "id": "VRUFpJWYeRRw"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}